{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b38328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import json\n",
    "\n",
    "\n",
    "#Loading mediapipe model \n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db12c75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmarks(image_rgb, pose_model): \n",
    "\n",
    "    '''\n",
    "    Get landmarks from a RGB image with a mediapipe model (already loaded)\n",
    "    Return: a numpy array (33,4) or None if landmarks are not found \n",
    "\n",
    "    Arguments : \n",
    "        image_rgb : a RGB image (numpy)\n",
    "        pose_model : mediapipe model \n",
    "    '''\n",
    "\n",
    "    results = pose_model.process(image_rgb)\n",
    "    \n",
    "    if results.pose_landmarks:\n",
    "\n",
    "        pose_np = np.array([[lm.x, lm.y, lm.z, lm.visibility] for lm in results.pose_landmarks.landmark])\n",
    "        return pose_np\n",
    "\n",
    "    return None\n",
    "\n",
    "def mmss(seconds) :\n",
    "\n",
    "    '''Convert a total number of seconds into a formatted \"MM:SS\" string.\n",
    "\n",
    "        Arguments:\n",
    "            seconds: Total seconds to convert (float). \n",
    "                    Negative values are handled as 0.\n",
    "\n",
    "        Return: A string formatted as \"MM:SS\" (e.g., \"02:05\")'''\n",
    "\n",
    "    s = max(0, int(seconds))\n",
    "    return f\"{s//60:02d}:{s%60:02d}\"\n",
    "\n",
    "def draw_rounded_rect(img, pt1, pt2, radius=22, color=(255, 200, 230), thickness=-1):\n",
    "\n",
    "    ''' Display a rectangle on a image with rounding borders \n",
    "\n",
    "    Arguments: \n",
    "        img: image numpy \n",
    "        pt1 , pt2 : tuple of coordonates , for example (x,y) \n",
    "        radius= int, defaut is 22\n",
    "        color= tuple of RGB colors, default is (255, 200, 230) (white)\n",
    "        thickness= default is  -1\n",
    "    '''\n",
    "    \n",
    "    x1, y1 = pt1\n",
    "    x2, y2 = pt2\n",
    "    radius = int(max(0, min(radius, abs(x2-x1)//2, abs(y2-y1)//2)))\n",
    "    if thickness < 0:\n",
    "        cv2.rectangle(img, (x1+radius, y1), (x2-radius, y2), color, -1)\n",
    "        cv2.rectangle(img, (x1, y1+radius), (x2, y2-radius), color, -1)\n",
    "        cv2.circle(img, (x1+radius, y1+radius), radius, color, -1)\n",
    "        cv2.circle(img, (x2-radius, y1+radius), radius, color, -1)\n",
    "        cv2.circle(img, (x1+radius, y2-radius), radius, color, -1)\n",
    "        cv2.circle(img, (x2-radius, y2-radius), radius, color, -1)\n",
    "    else:\n",
    "        cv2.rectangle(img, pt1, pt2, color, thickness)\n",
    "\n",
    "def put_fit_text(img, text, org, max_width, font=cv2.FONT_HERSHEY_SIMPLEX, base_scale=1.0, thickness=2, color=(60,30,60)):\n",
    "\n",
    "    '''\n",
    "    Draw text on an image and automatically scale it down if it exceeds a maximum width.\n",
    "\n",
    "    Arguments:\n",
    "        img: image numpy\n",
    "        text: string to display\n",
    "        org: tuple (x, y) for text position\n",
    "        max_width: maximum width in pixels allowed for the text\n",
    "        font: OpenCV font type\n",
    "        base_scale: initial font scale\n",
    "        thickness: line thickness\n",
    "        color: tuple of BGR colors\n",
    "    '''\n",
    "\n",
    "    (tw, th), _ = cv2.getTextSize(text, font, base_scale, thickness)\n",
    "    scale = base_scale if tw <= max_width else base_scale * (max_width / tw)\n",
    "    cv2.putText(img, text, org, font, scale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "def draw_session_card(frame, session, idx, paused=False, phase=\"HOLD\"):\n",
    "\n",
    "    '''\n",
    "    Display the yoga session information card (UI) on the frame.\n",
    "\n",
    "    Arguments:\n",
    "        frame: image numpy\n",
    "        session: list of dictionaries containing exercise data\n",
    "        idx: current exercise index\n",
    "        paused: boolean to indicate if the session is on pause\n",
    "        phase: current phase string (e.g., \"HOLD\", \"PREP\")\n",
    "    '''\n",
    "\n",
    "    x, y = 15, 15\n",
    "    box_w, box_h = 220, 70\n",
    "    draw_rounded_rect(frame, (x, y), (x+box_w, y+box_h), radius=12, color=(255, 245, 250), thickness=-1)\n",
    "    \n",
    "    cv2.putText(frame, \"YOGA\", (x+12, y+22), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (60,30,60), 1)\n",
    "    cv2.putText(frame, f\"{idx+1}/{len(session)}\", (x+box_w-45, y+22), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (60,30,60), 1)\n",
    "    \n",
    "    posture_name = session[idx][\"name\"].upper()\n",
    "    put_fit_text(frame, posture_name, (x+12, y+55), max_width=box_w-25, base_scale=0.8)\n",
    "    \n",
    "    status_text = \"PAUSED\" if paused else f\"STATUS: {phase}\"\n",
    "    cv2.putText(frame, status_text, (x+15, y+85), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (100, 0, 100), 1)\n",
    "\n",
    "def draw_progress_bar_bottom(frame, progress, right_text=\"\"):\n",
    "\n",
    "    '''\n",
    "    Draw a horizontal progress bar at the bottom of the screen.\n",
    "\n",
    "    Arguments:\n",
    "        frame: image numpy\n",
    "        progress: float between 0 and 1 representing the percentage\n",
    "        right_text: optional string to display inside the bar\n",
    "    '''\n",
    "\n",
    "    H, W = frame.shape[:2]\n",
    "    margin, bar_h = 25, 20\n",
    "    x, y, w = margin, H - 45, W - 2 * margin\n",
    "    cv2.rectangle(frame, (x, y), (x+w, y+bar_h), (240, 230, 240), -1) # BG\n",
    "    cv2.rectangle(frame, (x, y), (x+int(w*progress), y+bar_h), (80, 0, 80), -1) # Fill\n",
    "    cv2.rectangle(frame, (x, y), (x+w, y+bar_h), (60, 30, 60), 1) # Border\n",
    "    if right_text:\n",
    "        cv2.putText(frame, right_text, (x+3, y+15), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (220, 0, 220), 1)\n",
    "\n",
    "def draw_controls(image, is_paused):\n",
    "\n",
    "    '''\n",
    "    Display keyboard controls and a pause overlay if the session is paused.\n",
    "\n",
    "    Arguments:\n",
    "        image: image numpy\n",
    "        is_paused: boolean state of the application\n",
    "    '''\n",
    "\n",
    "\n",
    "    h, w, _ = image.shape\n",
    "    text = \"P:PAUSE  N:NEXT  Q:QUIT\"\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    scale = 0.4\n",
    "    thickness = 1\n",
    "    \n",
    "    (text_w, text_h), _ = cv2.getTextSize(text, font, scale, thickness)\n",
    "    \n",
    "    margin = 15\n",
    "    rect_x1, rect_y1 = w - text_w - 20, margin\n",
    "    rect_x2, rect_y2 = w - margin, margin + text_h + 12\n",
    "    \n",
    "    cv2.rectangle(image, (rect_x1, rect_y1), (rect_x2, rect_y2), (0, 0, 0), -1)\n",
    "    cv2.putText(image, text, (rect_x1 + 5, rect_y2 - 6), font, scale, (255, 255, 255), thickness)\n",
    "\n",
    "    if is_paused:\n",
    "        overlay = image.copy()\n",
    "        cv2.rectangle(overlay, (0, 0), (w, h), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.3, image, 0.7, 0, image)\n",
    "        cv2.putText(image, \"PAUSED\", (w//2 - 60, h//2), cv2.FONT_HERSHEY_DUPLEX, 1.2, (0, 0, 255), 3)\n",
    "\n",
    "def draw_end_screen(image):\n",
    "\n",
    "    '''\n",
    "    Display a full-screen summary overlay when the yoga session is finished.\n",
    "\n",
    "    Arguments:\n",
    "        image: image numpy\n",
    "    '''\n",
    "\n",
    "    h, w, _ = image.shape\n",
    "    overlay = image.copy()\n",
    "    cv2.rectangle(overlay, (0, 0), (w, h), (255, 240, 250), -1)\n",
    "    cv2.addWeighted(overlay, 0.8, image, 0.2, 0, image)\n",
    "    \n",
    "    cv2.putText(image, \"END !\", (w//2 - 100, h//2 - 60), cv2.FONT_HERSHEY_DUPLEX, 2.5, (60, 30, 60), 5)\n",
    "    cv2.putText(image, \"FINISHED ! \", (w//2 - 150, h//2 + 20), cv2.FONT_HERSHEY_DUPLEX, 1.5, (60, 30, 60), 3)\n",
    "    cv2.putText(image, \"BRAVO !\", (w//2 - 110, h//2 + 90), cv2.FONT_HERSHEY_DUPLEX, 1.2, (100, 0, 100), 2)\n",
    "    cv2.putText(image, \"Put 'Q' to quit\", (w//2 - 115, h - 50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (50, 50, 50), 1)\n",
    "\n",
    "def change_duration(session, posture, duration):\n",
    "    '''\n",
    "    Changes the duration of a specific posture in the session list.\n",
    "    Returns True if found and changed, False otherwise.\n",
    "    '''\n",
    "    \n",
    "    found = False\n",
    "    for item in session:\n",
    "        if item['name'].strip().lower() == posture.strip().lower():\n",
    "            item['duration'] = max(0, int(duration))\n",
    "            found = True\n",
    "            \n",
    "    if not found:\n",
    "        print(f\"Warning: Posture '{posture}' not found in session.\")\n",
    "        \n",
    "    return found\n",
    "\n",
    "def delete_pose(session, posture):\n",
    "    '''\n",
    "    Delete a pose in the session.\n",
    "    Return the updated session.\n",
    "    '''\n",
    "\n",
    "    target = posture.strip().lower()\n",
    "    initial_count = len(session)\n",
    "\n",
    "    session[:] = [p for p in session if p['name'].strip().lower() != target]\n",
    "    \n",
    "    if len(session) == initial_count:\n",
    "        print(f\"Warning: Posture '{posture}' not found in session.\")\n",
    "        \n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00918782",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('yoga_config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "labels = config['labels']\n",
    "model = tf.keras.models.load_model(config['model_path'])\n",
    "\n",
    "cfg = json.load(open(\"yoga_config.json\", \"r\", encoding=\"utf-8\"))\n",
    "logos = np.load(cfg[\"logos_npz_path\"])  # dict-like\n",
    "pose_logo = {}\n",
    "for name in logos: \n",
    "    pose_logo[name] = logos[name]    \n",
    "    \n",
    "session = [{'name' :i , \"duration\" : 15} for i in config['labels']]\n",
    "\n",
    "# change_duration(session, posture, duration) \n",
    "session = delete_pose(session, 'cobra')\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cam_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "cam_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "zoom = 1.2\n",
    "cv2.namedWindow(\"Yoga postures\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"Yoga postures\", int(cam_w*zoom), int(cam_h*zoom))\n",
    "\n",
    "\n",
    "x = 250\n",
    "y = 10\n",
    "\n",
    "\n",
    "idx = 0\n",
    "paused = False\n",
    "start_time = None\n",
    "elapsed_time = 0\n",
    "is_preparing = True\n",
    "is_finished = False \n",
    "prep_duration = 10 \n",
    "prep_start_time = time.time()\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose_model:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret: break\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose_model.process(image_rgb)\n",
    "        landmarks_np = get_landmarks(image_rgb, pose_model)\n",
    "        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "        phase = \"WAITING...\"\n",
    "        progress = 0\n",
    "\n",
    "        if is_finished:\n",
    "            draw_end_screen(image_bgr)\n",
    "            progress = 1 \n",
    "\n",
    "        elif is_preparing:\n",
    "            \n",
    "            current_pose_name = session[idx]['name']\n",
    "            \n",
    "            if current_pose_name in pose_logo:\n",
    "                img_to_show = pose_logo[current_pose_name]\n",
    "                h_img, w_img, _ = img_to_show.shape\n",
    "                image_bgr[y : y+h_img, x : x+w_img] = img_to_show\n",
    "\n",
    "\n",
    "            elapsed_prep = time.time() - prep_start_time\n",
    "            countdown = int(prep_duration - elapsed_prep)\n",
    "            \n",
    "            cv2.putText(image_bgr, f\"GOT READY : {session[idx]['name']}\", (cam_w//2-180, cam_h//2-40), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            cv2.putText(image_bgr, str(countdown if countdown > 0 else \"GO!\"), (cam_w//2-30, cam_h//2+60), \n",
    "                        cv2.FONT_HERSHEY_DUPLEX, 2, (0, 255, 0), 4)\n",
    "            \n",
    "            if elapsed_prep >= prep_duration:\n",
    "                is_preparing = False\n",
    "                start_time = None \n",
    "                elapsed_time = 0\n",
    "\n",
    "        else:\n",
    "\n",
    "            is_pose_correct = False\n",
    "\n",
    "            if not paused:\n",
    "\n",
    "\n",
    "                # # Modele prediction posture \n",
    "                if landmarks_np is not None:\n",
    "                    input_data = landmarks_np.flatten().reshape(1, -1) #format (33,4) --> (1, 132)\n",
    "                    \n",
    "                    prediction = model.predict(input_data, verbose=0)\n",
    "                    predicted_idx = np.argmax(prediction)\n",
    "                    confidence = prediction[0][predicted_idx]\n",
    "                    \n",
    "                    current_target_name = session[idx][\"name\"]\n",
    "                    predicted_name = labels[predicted_idx]\n",
    "                    \n",
    "                if predicted_name == current_target_name and confidence > 0.8:\n",
    "                    is_pose_correct = True\n",
    "\n",
    "                #is_pose_correct = False\n",
    "                #is_pose_correct = landmarks_np is not None # to test the model \n",
    "                \n",
    "                if is_pose_correct:\n",
    "                    phase = \"HOLDING\"\n",
    "\n",
    "                    now = time.time()\n",
    "                    if start_time is None: \n",
    "\n",
    "                        start_time = now\n",
    "                    \n",
    "                    delta = now - start_time\n",
    "                    elapsed_time += delta  \n",
    "                    start_time = now       \n",
    "\n",
    "\n",
    "                    target_duration = session[idx][\"duration\"]\n",
    "                    progress = np.clip(elapsed_time / target_duration, 0, 1)\n",
    "\n",
    "                    if elapsed_time >= target_duration:\n",
    "                        if idx < len(session) - 1:\n",
    "                            idx += 1\n",
    "                            is_preparing = True\n",
    "                            prep_start_time = time.time()\n",
    "                            start_time = None\n",
    "                            elapsed_time = 0\n",
    "                        else:\n",
    "                            is_finished = True \n",
    "                else:\n",
    "                    start_time = None\n",
    "\n",
    "            # if results.pose_landmarks:\n",
    "            #     mp_drawing.draw_landmarks(image_bgr, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            \n",
    "        draw_session_card(image_bgr, session, idx, paused=paused, phase=phase)\n",
    "        remaining_time = max(0, session[idx][\"duration\"] - elapsed_time)\n",
    "        draw_progress_bar_bottom(image_bgr, progress, right_text=mmss(remaining_time))\n",
    "        draw_controls(image_bgr, paused)\n",
    "        cv2.imshow('Yoga postures', image_bgr)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'): break\n",
    "        elif key == ord('p'): paused = not paused\n",
    "        elif key == ord('n'):\n",
    "            if idx < len(session) - 1:\n",
    "                idx += 1\n",
    "                is_preparing = True\n",
    "                prep_start_time = time.time()\n",
    "                start_time = None\n",
    "                elapsed_time = 0\n",
    "            else:\n",
    "                is_finished = True\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mediapipe-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
