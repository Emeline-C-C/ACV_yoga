{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d544e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed6845e",
   "metadata": {},
   "source": [
    "# Preprocessing des datas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0da838cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def get_landmarks(image_rgb, pose_model): \n",
    "    '''\n",
    "    Récupère les landmarks d'une image donnée en RGB via un modèle déjà chargé.\n",
    "    Return: un numpy array (33,4) ou None si rien n'est trouvé.\n",
    "    '''\n",
    "\n",
    "    results = pose_model.process(image_rgb)\n",
    "    \n",
    "    if results.pose_landmarks:\n",
    "\n",
    "        pose_np = np.array([[lm.x, lm.y, lm.z, lm.visibility] for lm in results.pose_landmarks.landmark])\n",
    "        return pose_np\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "009d424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(folder_path, path_save, pickle_name=\"dataset.pkl\"): \n",
    "    ''' récupère les landmarks d'images dans un dossier via la fonction get_landmarks(image)\n",
    "\n",
    "    folder_path : dossier où sont les images\n",
    "    path_save   : dossier où sauvegarder le pickle\n",
    "    pickle_name : nom du fichier pickle\n",
    "\n",
    "    return: numpy array de shape (N, 132) si flatten (33*4)\n",
    "    '''\n",
    "\n",
    "    mp_pose = mp.solutions.pose\n",
    "    os.makedirs(path_save, exist_ok=True)\n",
    "\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        data_list = []\n",
    "        fichiers = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        fichiers.sort()\n",
    "\n",
    "        path_save_pickle = os.path.join(path_save, pickle_name)\n",
    "\n",
    "        for name in fichiers:\n",
    "            img_path = os.path.join(folder_path, name)\n",
    "            img = cv2.imread(img_path)\n",
    "\n",
    "            if img is None:\n",
    "                print(f\"Impossible de lire : {img_path}\")\n",
    "                continue\n",
    "\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            landmarks_vector = get_landmarks(img_rgb, pose)\n",
    "\n",
    "            if landmarks_vector is not None:\n",
    "                data_list.append(landmarks_vector.flatten())  # (132,)\n",
    "            else:\n",
    "                print(f\"Ignorée (pas de pose détectée) : {name}\")\n",
    "\n",
    "        dataset = np.array(data_list, dtype=np.float32)\n",
    "\n",
    "        with open(path_save_pickle, 'wb') as f:\n",
    "            pickle.dump(dataset, f)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d69193",
   "metadata": {},
   "source": [
    "## attributs target  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27d4623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(dataset, class_int): \n",
    "    ''''récupère la target du dataset'''\n",
    "\n",
    "    nb_images = dataset.shape[0]\n",
    "    class_id = class_int\n",
    "    target = np.full(nb_images, class_id)\n",
    "\n",
    "    return target \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec2f1c1",
   "metadata": {},
   "source": [
    "# Build dataset et concatenisation en numpy array#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0c950bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_full_dataset(data_root, path_save, poses=(\"cobra\", \"tree\", \"downdog\",\"forwardfold\",\"chair\",\n",
    "                                                    \"warrior1\",\"warrior2\",\"warrior3\",\"plank\",\"child\",\"lotus\")):\n",
    "    \"\"\"\n",
    "    Construit X, y à partir de dossiers:\n",
    "      data_root/cobra, data_root/tree, data_root/downdog\n",
    "\n",
    "    Retour:\n",
    "      X (N,132), y (N,)\n",
    "    + sauvegarde un pickle par pose (comme vous faites déjà)\n",
    "    \"\"\"\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for class_id, pose_name in enumerate(poses):\n",
    "        folder_path = os.path.join(data_root, pose_name)\n",
    "\n",
    "        ds = get_dataset(\n",
    "            folder_path=folder_path,\n",
    "            path_save=path_save,\n",
    "            pickle_name=f\"dataset_{pose_name}.pkl\"\n",
    "        )\n",
    "\n",
    "        target = get_target(ds, class_id)\n",
    "\n",
    "        X_list.append(ds)\n",
    "        y_list.append(target)\n",
    "\n",
    "    X = np.vstack(X_list).astype(np.float32)\n",
    "    y = np.concatenate(y_list).astype(np.int64)\n",
    "\n",
    "    # (optionnel) sauvegarde globale\n",
    "    with open(os.path.join(path_save, \"X_all.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(X, f)\n",
    "    with open(os.path.join(path_save, \"y_all.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(y, f)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978ad46e",
   "metadata": {},
   "source": [
    "# Dataset des postures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1570f255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignorée (pas de pose détectée) : 1_364.jpg\n",
      "Ignorée (pas de pose détectée) : 3_287.jpg\n",
      "Ignorée (pas de pose détectée) : File26.png\n",
      "Ignorée (pas de pose détectée) : File57.png\n",
      "Ignorée (pas de pose détectée) : File59.png\n",
      "Ignorée (pas de pose détectée) : File63.png\n",
      "Ignorée (pas de pose détectée) : File68.jpeg\n",
      "Ignorée (pas de pose détectée) : PXL_20251217_103746696.MP.jpg\n",
      "Ignorée (pas de pose détectée) : image13.jpeg\n",
      "Ignorée (pas de pose détectée) : images51.jpg\n",
      "Ignorée (pas de pose détectée) : 00000104.jpg\n",
      "Ignorée (pas de pose détectée) : 00000202.jpg\n",
      "Ignorée (pas de pose détectée) : images133.jpg\n",
      "Ignorée (pas de pose détectée) : images216.jpg\n",
      "Ignorée (pas de pose détectée) : images54.jpg\n",
      "Ignorée (pas de pose détectée) : downdog (16).jpg\n",
      "Ignorée (pas de pose détectée) : downdog (25).jpg\n",
      "Ignorée (pas de pose détectée) : downdog (55).jpg\n",
      "Ignorée (pas de pose détectée) : downdog (68).jpg\n",
      "Ignorée (pas de pose détectée) : downdog (85).jpg\n",
      "Ignorée (pas de pose détectée) : downdog (92).jpg\n",
      "Ignorée (pas de pose détectée) : File70.jpeg\n",
      "Ignorée (pas de pose détectée) : File12.png\n",
      "Ignorée (pas de pose détectée) : File2.png\n",
      "Ignorée (pas de pose détectée) : File27.png\n",
      "Ignorée (pas de pose détectée) : File31.png\n",
      "Ignorée (pas de pose détectée) : File4.png\n",
      "Ignorée (pas de pose détectée) : File5.png\n",
      "Ignorée (pas de pose détectée) : File62.png\n",
      "Ignorée (pas de pose détectée) : File67.png\n",
      "Ignorée (pas de pose détectée) : File78.jpeg\n",
      "Ignorée (pas de pose détectée) : 1_125.jpg\n",
      "Ignorée (pas de pose détectée) : 1_25.jpg\n",
      "Ignorée (pas de pose détectée) : 1_321.jpg\n",
      "Ignorée (pas de pose détectée) : 1_497.jpg\n",
      "Ignorée (pas de pose détectée) : 1_509.jpg\n",
      "Ignorée (pas de pose détectée) : 1_619.jpg\n",
      "Ignorée (pas de pose détectée) : 1_625.jpg\n",
      "Ignorée (pas de pose détectée) : 1_751.jpg\n",
      "Ignorée (pas de pose détectée) : 1_95.jpg\n",
      "Ignorée (pas de pose détectée) : warrior1 (1).jpeg\n",
      "Ignorée (pas de pose détectée) : warrior1 (33).jpg\n",
      "Ignorée (pas de pose détectée) : warrior1 (53).jpg\n",
      "Ignorée (pas de pose détectée) : warrior1 (56).jpg\n",
      "Ignorée (pas de pose détectée) : File22.png\n",
      "Ignorée (pas de pose détectée) : File34.png\n",
      "Ignorée (pas de pose détectée) : File41.png\n",
      "Ignorée (pas de pose détectée) : File44.png\n",
      "Ignorée (pas de pose détectée) : File8.png\n",
      "Ignorée (pas de pose détectée) : File28.png\n",
      "Ignorée (pas de pose détectée) : File41.png\n",
      "Ignorée (pas de pose détectée) : File46.png\n",
      "Ignorée (pas de pose détectée) : File5.png\n",
      "Ignorée (pas de pose détectée) : File54.jpg\n",
      "Ignorée (pas de pose détectée) : File65.jpeg\n",
      "Ignorée (pas de pose détectée) : File26.png\n",
      "Ignorée (pas de pose détectée) : File34.png\n",
      "Ignorée (pas de pose détectée) : File75.jpeg\n",
      "(992, 132) (992,)\n"
     ]
    }
   ],
   "source": [
    "path_data = r'C:\\Users\\mvana\\Documents\\Formation data scientist\\20. ACV\\Posture_yoga\\data'\n",
    "path_save = \"datasets\"\n",
    "\n",
    "X, y = build_full_dataset(path_data, path_save)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcefad1",
   "metadata": {},
   "source": [
    "# Vérification de la sortie #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa630bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(992,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chemin_du_fichier = r'C:\\Users\\mvana\\Documents\\Formation data scientist\\20. ACV\\ACV_yoga\\datasets\\Y_all.pkl'\n",
    "\n",
    "with open(chemin_du_fichier, 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0ca71ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(992,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_target(dataset, 1).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mediapipe-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
